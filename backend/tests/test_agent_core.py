import pytest
from unittest.mock import AsyncMock, patch, MagicMock
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama

from app.agent.core import get_llm, create_agent_executor, process_message

class TestGetLLM:
    """LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸"""
    
    # def test_get_llm_openai(self):
    #     """OpenAI LLM ìƒì„± í™•ì¸"""
    #     llm = get_llm("openai")
    #     assert isinstance(llm, ChatOpenAI)
    #     assert llm.model_name == "gpt-4o"
    #     assert llm.temperature == 0.5
    
    def test_get_llm_ollama(self):
        """Ollama LLM ìƒì„± í™•ì¸"""
        llm = get_llm("ollama")
        assert isinstance(llm, ChatOllama)
        assert llm.model == "gpt-oss:20b"
        assert llm.temperature == 0.5
    
    # def test_get_llm_invalid_type(self):
    #     """ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM íƒ€ìž… ì—ëŸ¬ í™•ì¸"""
    #     with pytest.raises(ValueError, match="ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM íƒ€ìž…"):
    #         get_llm("invalid_type")


class TestCreateAgentExecutor:
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± í…ŒìŠ¤íŠ¸"""
    
    def test_create_agent_executor_returns_agent(self):
        """ì—ì´ì „íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸"""
        agent = create_agent_executor("ollama")
        assert agent is not None
        # Agent should be callable/invokable
        assert hasattr(agent, 'ainvoke') or hasattr(agent, 'astream')


class TestProcessMessage:
    """ë©”ì‹œì§€ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_process_message_without_history(self):
        """ížˆìŠ¤í† ë¦¬ ì—†ì´ ë©”ì‹œì§€ ì²˜ë¦¬"""
        # Mock the agent executor
        mock_chunk = {"output": "í…ŒìŠ¤íŠ¸ ì‘ë‹µìž…ë‹ˆë‹¤"}
        
        with patch('app.agent.core.create_agent_executor') as mock_create:
            mock_executor = MagicMock()
            
            async def mock_astream(*args, **kwargs):
                yield mock_chunk
            
            mock_executor.astream = mock_astream
            mock_create.return_value = mock_executor
            
            result = []
            async for chunk in process_message("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸"):
                result.append(chunk)
            
            assert len(result) == 1
            assert result[0] == "í…ŒìŠ¤íŠ¸ ì‘ë‹µìž…ë‹ˆë‹¤"
    
    @pytest.mark.asyncio
    async def test_process_message_with_history(self):
        """ížˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ë©”ì‹œì§€ ì²˜ë¦¬"""
        history = [
            ("user", "ì•ˆë…•í•˜ì„¸ìš”"),
            ("assistant", "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
        ]
        
        mock_chunk = {"output": "ë„¤, ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"}
        
        with patch('app.agent.core.create_agent_executor') as mock_create:
            mock_executor = MagicMock()
            
            async def mock_astream(*args, **kwargs):
                # Verify history was passed
                assert "chat_history" in kwargs or (args and "chat_history" in args[0])
                yield mock_chunk
            
            mock_executor.astream = mock_astream
            mock_create.return_value = mock_executor
            
            result = []
            async for chunk in process_message("ë„ì™€ì£¼ì„¸ìš”", history):
                result.append(chunk)
            
            assert len(result) == 1
            assert result[0] == "ë„¤, ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"


class TestIntegration:
    """í†µí•© í…ŒìŠ¤íŠ¸ - ì‹¤ì œ AI í˜¸ì¶œ (ìˆ˜ë™ ì‹¤í–‰ìš©)"""
    
    @pytest.mark.skip(reason="ì‹¤ì œ AIë¥¼ í˜¸ì¶œí•˜ë¯€ë¡œ ìˆ˜ë™ìœ¼ë¡œë§Œ ì‹¤í–‰")
    @pytest.mark.asyncio
    async def test_real_agent_execution(self):
        """ì‹¤ì œ Ollama/OpenAI í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
        print("\nðŸ¤– ì‹¤ì œ AI ì‘ë‹µ í…ŒìŠ¤íŠ¸:\n")
        
        full_response = ""
        async for chunk in process_message("ì•ˆë…•í•˜ì„¸ìš”"):
            print(chunk, end="", flush=True)
            full_response += chunk
        
        print(f"\n\nâœ… ì‘ë‹µ ì™„ë£Œ! (ì´ {len(full_response)}ìž)")
        assert len(full_response) > 0
    
    @pytest.mark.skip(reason="ë²¡í„° DB ê²€ìƒ‰ í¬í•¨í•˜ë¯€ë¡œ ìˆ˜ë™ìœ¼ë¡œë§Œ ì‹¤í–‰")
    @pytest.mark.asyncio
    async def test_vector_db_search_integration(self):
        """ë²¡í„° DB ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‹¤ì œë¡œ í˜¸ì¶œí•˜ëŠ” í…ŒìŠ¤íŠ¸"""
        print("\nðŸ” ë²¡í„° DB ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:\n")
        
        query = "í•­ê³µê¸° ì†Œìž¬ì— ëŒ€í•œ íŠ¹í—ˆ"
        
        full_response = ""
        async for chunk in process_message(query):
            print(chunk, end="", flush=True)
            full_response += chunk
        
        print(f"\n\nâœ… ì‘ë‹µ ì™„ë£Œ! (ì´ {len(full_response)}ìž)")
        
        # ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ê°€ í¬í•¨ë˜ì–´ ìžˆì–´ì•¼ í•¨
        assert len(full_response) > 0
